from deep_translator import GoogleTranslator
import re
import os
import glob
import argparse
import time

def is_number_or_scientific(text):
    """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦ä¸ºæ•°å­—æˆ–ç§‘å­¦è®¡æ•°æ³•ï¼ˆä»¥Eæˆ–Nç»“å°¾çš„æ•°å­—ï¼‰"""
    text = text.strip()
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºç©ºæˆ–åªæœ‰ç¬¦å·
    if not text or text in ['-', '+']:
        return True
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºçº¯æ•°å­—ï¼ˆåŒ…æ‹¬è´Ÿæ•°ï¼‰
    if text.lstrip('-+').isdigit():
        return True
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºå°æ•°ï¼ˆåŒ…æ‹¬è´Ÿæ•°å’Œä½¿ç”¨é€—å·ä½œä¸ºå°æ•°ç‚¹çš„æ¬§å¼æ ¼å¼ï¼‰
    try:
        # å°è¯•è§£ææ ‡å‡†å°æ•°æ ¼å¼
        float(text)
        return True
    except ValueError:
        try:
            # å°è¯•è§£ææ¬§å¼å°æ•°æ ¼å¼ï¼ˆé€—å·ä½œä¸ºå°æ•°ç‚¹ï¼‰
            float(text.replace(',', '.'))
            return True
        except ValueError:
            pass
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºç§‘å­¦è®¡æ•°æ³•ï¼ˆä»¥Eç»“å°¾ï¼‰
    if text.upper().endswith('E') or re.match(r'^[+-]?\d+\.?\d*E[+-]?\d*$', text.upper()):
        return True
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºä»¥Eæˆ–Nç»“å°¾çš„æ•°å­—
    if re.match(r'^[+-]?\d+[EN]$', text.upper()):
        return True
    
    # æ£€æŸ¥æ˜¯å¦ä¸ºåˆ†æ•°æ ¼å¼ï¼ˆå¦‚ 3/4ï¼‰
    if re.match(r'^\d+/\d+$', text):
        return True
        
    return False

def extract_translatable_content(file_path):
    """æå–æ–‡ä»¶ä¸­éœ€è¦ç¿»è¯‘çš„å†…å®¹"""
    translatable_items = []
    
    try:
        # å°è¯•ä¸åŒçš„ç¼–ç 
        encodings = ['utf-8', 'utf-16', 'latin-1', 'cp1252']
        content = None
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    content = f.readlines()
                break
            except UnicodeDecodeError:
                continue
        
        if content is None:
            print(f"âš ï¸ æ— æ³•è¯»å–æ–‡ä»¶ {file_path}ï¼Œè·³è¿‡")
            return []
        
        for line_num, line in enumerate(content):
            original_line = line
            line = line.strip()
            
            # è·³è¿‡ç©ºè¡Œã€æ³¨é‡Šè¡Œå’ŒèŠ‚æ ‡é¢˜
            if not line or line.startswith('#') or line.startswith('[') or line.startswith('//'):
                continue
            
            # æŸ¥æ‰¾ç­‰å·åˆ†å‰²çš„è¡Œ
            if '=' in line:
                key, value = line.split('=', 1)
                value = value.strip()
                
                # è·³è¿‡ç©ºå€¼ã€æ–‡ä»¶è·¯å¾„ã€æ•°å­—å’Œç§‘å­¦è®¡æ•°æ³•
                if (not value or 
                    value.startswith('C:\\') or 
                    is_number_or_scientific(value) or
                    len(value) < 2):
                    continue
                
                # è·³è¿‡å¸¦æœ‰è‹±æ–‡ä¸­æ‹¬å·çš„å†…å®¹
                if '[' in value and ']' in value:
                    continue
                
                # åªç¿»è¯‘åŒ…å«å­—æ¯çš„æ–‡æœ¬
                if re.search(r'[a-zA-Z]', value) and not value.startswith('http'):
                    translatable_items.append({
                        'file_path': file_path,
                        'line_num': line_num,
                        'key': key.strip(),
                        'value': value,
                        'original_line': original_line,
                        'type': 'key_value'
                    })
            
            # å¤„ç†åˆ†å·åˆ†éš”çš„æ•°æ®ï¼ˆå¦‚CSVæ ¼å¼ï¼‰
            elif ';' in line:
                parts = line.split(';')
                # æ£€æŸ¥æ‰€æœ‰åˆ—ï¼Œä½†è·³è¿‡æ‰€æœ‰æ•°å­—
                for col_index, part in enumerate(parts):
                    part = part.strip()
                    
                    # è·³è¿‡ç©ºå€¼ã€æ•°å­—ã€ç§‘å­¦è®¡æ•°æ³•å’ŒçŸ­æ–‡æœ¬
                    if (not part or 
                        part == '-' or
                        is_number_or_scientific(part) or
                        len(part) < 2):
                        continue
                    
                    # è·³è¿‡å¸¦æœ‰è‹±æ–‡ä¸­æ‹¬å·çš„å†…å®¹
                    if '[' in part and ']' in part:
                        continue
                    
                    # åªç¿»è¯‘åŒ…å«å­—æ¯çš„æ–‡æœ¬ï¼ˆæ’é™¤çº¯æ•°å­—ï¼‰
                    if re.search(r'[a-zA-Z]', part):
                        translatable_items.append({
                            'file_path': file_path,
                            'line_num': line_num,
                            'value': part,
                            'original_line': original_line,
                            'type': 'csv_cell',
                            'column_index': col_index
                        })
            
            # æŸ¥æ‰¾å†’å·åˆ†å‰²çš„è¡Œï¼ˆæ²¡æœ‰ç­‰å·çš„æƒ…å†µï¼‰
            elif ': ' in line:
                parts = line.split(': ', 1)
                if len(parts) == 2:
                    key, value = parts
                    value = value.strip()
                    
                    # è·³è¿‡ç©ºå€¼ã€æ•°å­—å’Œç§‘å­¦è®¡æ•°æ³•
                    if (not value or 
                        is_number_or_scientific(value) or
                        len(value) < 2):
                        continue
                    
                    # è·³è¿‡å¸¦æœ‰è‹±æ–‡ä¸­æ‹¬å·çš„å†…å®¹
                    if '[' in value and ']' in value:
                        continue
                    
                    # åªç¿»è¯‘åŒ…å«å­—æ¯çš„æ–‡æœ¬
                    if re.search(r'[a-zA-Z]', value):
                        translatable_items.append({
                            'file_path': file_path,
                            'line_num': line_num,
                            'key': key.strip(),
                            'value': value,
                            'original_line': original_line,
                            'type': 'colon_value'
                        })
            
            # æ²¡æœ‰ç­‰å·å’Œå†’å·çš„è¡Œï¼Œç›´æ¥ç¿»è¯‘
            else:
                # è·³è¿‡å¸¦æœ‰è‹±æ–‡ä¸­æ‹¬å·çš„å†…å®¹
                if '[' in line and ']' in line:
                    continue
                
                # åªç¿»è¯‘åŒ…å«å­—æ¯ä¸”é•¿åº¦åˆé€‚çš„æ–‡æœ¬
                if re.search(r'[a-zA-Z]', line) and len(line) >= 2:
                    translatable_items.append({
                        'file_path': file_path,
                        'line_num': line_num,
                        'value': line,
                        'original_line': original_line,
                        'type': 'full_line'
                    })
    
    except Exception as e:
        print(f"âŒ å¤„ç†æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")
    
    return translatable_items

def translate_texts_in_blocks(texts, max_block_size=3000, max_retries=3):
    """åˆ†å—ç¿»è¯‘æ–‡æœ¬åˆ—è¡¨ï¼Œæ”¯æŒç½‘ç»œé”™è¯¯é‡è¯•"""
    translated_texts = []
    
    current_block = []
    current_length = 0
    block_count = 0
    
    def translate_block_with_retry(block_text, block_num, retry_count=0):
        """å¸¦é‡è¯•æœºåˆ¶çš„å—ç¿»è¯‘å‡½æ•°"""
        try:
            translated_block = GoogleTranslator(source='auto', target='zh-CN').translate(block_text)
            return translated_block
        except Exception as e:
            error_msg = str(e).lower()
            # æ£€æŸ¥æ˜¯å¦ä¸ºç½‘ç»œç›¸å…³é”™è¯¯
            if any(keyword in error_msg for keyword in ['network', 'connection', 'timeout', 'ssl', 'handshake', 'keyboardinterrupt']):
                if retry_count < max_retries:
                    wait_time = (retry_count + 1) * 2  # é€’å¢ç­‰å¾…æ—¶é—´
                    print(f"âš ï¸ ç¬¬ {block_num} å—ç½‘ç»œé”™è¯¯ï¼Œ{wait_time}ç§’åé‡è¯• (ç¬¬{retry_count + 1}æ¬¡é‡è¯•): {e}")
                    time.sleep(wait_time)
                    return translate_block_with_retry(block_text, block_num, retry_count + 1)
                else:
                    print(f"âŒ ç¬¬ {block_num} å—é‡è¯•{max_retries}æ¬¡åä»å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡: {e}")
                    return None
            else:
                print(f"âŒ ç¬¬ {block_num} å—ç¿»è¯‘å¤±è´¥ï¼ˆéç½‘ç»œé”™è¯¯ï¼‰ï¼Œä½¿ç”¨åŸæ–‡: {e}")
                return None
    
    for i, text in enumerate(texts):
        # å¦‚æœåŠ ä¸Šå½“å‰æ–‡æœ¬ä¼šè¶…å‡ºé™åˆ¶ï¼Œå…ˆç¿»è¯‘å½“å‰å—
        if current_length + len(text) > max_block_size and current_block:
            block_count += 1
            progress = (i / len(texts)) * 100
            print(f"ğŸ”„ ç¿»è¯‘ç¬¬ {block_count} å— ({len(current_block)} ä¸ªæ–‡æœ¬, {current_length} å­—ç¬¦) - è¿›åº¦: {progress:.1f}%")
            
            # ç¿»è¯‘å½“å‰å—
            block_text = "\n\n".join(current_block)
            translated_block = translate_block_with_retry(block_text, block_count)
            
            if translated_block:
                block_translations = translated_block.strip().split("\n\n")
                
                # ç¡®ä¿ç¿»è¯‘ç»“æœæ•°é‡åŒ¹é…
                while len(block_translations) < len(current_block):
                    block_translations.append(current_block[len(block_translations)])
                
                translated_texts.extend(block_translations[:len(current_block)])
                print(f"âœ… ç¬¬ {block_count} å—ç¿»è¯‘å®Œæˆ")
            else:
                # ç¿»è¯‘å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡
                translated_texts.extend(current_block)
            
            # é‡ç½®å½“å‰å—
            current_block = []
            current_length = 0
        
        # æ·»åŠ å½“å‰æ–‡æœ¬åˆ°å—ä¸­
        current_block.append(text)
        current_length += len(text) + 2  # +2 for "\n\n"
    
    # ç¿»è¯‘æœ€åä¸€ä¸ªå—
    if current_block:
        block_count += 1
        print(f"ğŸ”„ ç¿»è¯‘ç¬¬ {block_count} å— ({len(current_block)} ä¸ªæ–‡æœ¬, {current_length} å­—ç¬¦) - æœ€åä¸€å—")
        
        block_text = "\n\n".join(current_block)
        translated_block = translate_block_with_retry(block_text, block_count)
        
        if translated_block:
            block_translations = translated_block.strip().split("\n\n")
            
            while len(block_translations) < len(current_block):
                block_translations.append(current_block[len(block_translations)])
            
            translated_texts.extend(block_translations[:len(current_block)])
            print(f"âœ… ç¬¬ {block_count} å—ç¿»è¯‘å®Œæˆ")
        else:
            # ç¿»è¯‘å¤±è´¥ï¼Œä½¿ç”¨åŸæ–‡
            translated_texts.extend(current_block)
    
    if block_count > 0:
        print(f"ğŸ‰ æ‰€æœ‰ {block_count} ä¸ªå—ç¿»è¯‘å®Œæˆï¼")
    
    return translated_texts

def update_file_with_translations(file_path, updates):
    """ç”¨ç¿»è¯‘ç»“æœæ›´æ–°æ–‡ä»¶"""
    try:
        # è¯»å–åŸæ–‡ä»¶
        encodings = ['utf-8', 'utf-16', 'latin-1', 'cp1252']
        content = None
        used_encoding = None
        
        for encoding in encodings:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    content = f.readlines()
                used_encoding = encoding
                break
            except UnicodeDecodeError:
                continue
        
        if content is None:
            print(f"âŒ æ— æ³•è¯»å–æ–‡ä»¶ {file_path}")
            return
        
        # åº”ç”¨ç¿»è¯‘
        for update in updates:
            line_num = update['line_num']
            translated_value = update['translated_value']
            update_type = update['type']
            
            if line_num < len(content):
                if update_type == 'key_value':
                    # é”®å€¼å¯¹æ ¼å¼
                    key = update['key']
                    new_line = f"{key}={translated_value}\n"
                elif update_type == 'colon_value':
                    # å†’å·åˆ†å‰²æ ¼å¼
                    key = update['key']
                    new_line = f"{key}: {translated_value}\n"
                elif update_type == 'csv_cell':
                    # CSVæ ¼å¼ï¼Œéœ€è¦æ›¿æ¢ç‰¹å®šåˆ—
                    original_line = update['original_line']
                    parts = original_line.strip().split(';')
                    col_index = update['column_index']
                    if col_index < len(parts):
                        parts[col_index] = translated_value
                    new_line = ';'.join(parts) + '\n'
                elif update_type == 'full_line':
                    # æ•´è¡Œç¿»è¯‘
                    new_line = f"{translated_value}\n"
                
                content[line_num] = new_line
        
        # å†™å…¥ç¿»è¯‘åçš„æ–‡ä»¶
        output_file = file_path.replace('.dat', '_translated.dat').replace('.txt', '_translated.txt')
        
        # å¼ºåˆ¶ä½¿ç”¨UTF-8ç¼–ç ä¿å­˜ç¿»è¯‘åçš„æ–‡ä»¶ï¼Œé¿å…ä¸­æ–‡å­—ç¬¦ç¼–ç é—®é¢˜
        with open(output_file, 'w', encoding='utf-8') as f:
            f.writelines(content)
        
        print(f"âœ… å·²æ›´æ–°æ–‡ä»¶: {output_file} ({len(updates)} ä¸ªç¿»è¯‘é¡¹)")
        
    except Exception as e:
        print(f"âŒ æ›´æ–°æ–‡ä»¶ {file_path} æ—¶å‡ºé”™: {e}")



def process_files_batch(file_pattern=None, max_files=None, start_index=0):
    """åˆ†æ‰¹å¤„ç†æ–‡ä»¶"""
    # è·å–æ‰€æœ‰.datå’Œ.txtæ–‡ä»¶
    if file_pattern:
        dat_files = glob.glob(f"*{file_pattern}*.dat")
        txt_files = glob.glob(f"*{file_pattern}*.txt")
    else:
        dat_files = glob.glob("*.dat")
        txt_files = glob.glob("*.txt")
    
    all_files = dat_files + txt_files
    
    # æ’é™¤å·²ç¿»è¯‘çš„æ–‡ä»¶
    all_files = [f for f in all_files if not f.endswith('_translated.dat') and not f.endswith('_translated.txt')]
    
    if start_index > 0:
        all_files = all_files[start_index:]
    
    if max_files:
        all_files = all_files[:max_files]
    
    if not all_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…çš„.datæˆ–.txtæ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶å¾…å¤„ç†")
    
    # åˆ†ææ¯ä¸ªæ–‡ä»¶
    files_with_content = []
    files_without_content = []
    
    for file_path in all_files:
        print(f"ğŸ“– åˆ†ææ–‡ä»¶: {file_path}")
        items = extract_translatable_content(file_path)
        if items:
            files_with_content.append((file_path, items))
            print(f"   æ‰¾åˆ° {len(items)} ä¸ªå¾…ç¿»è¯‘é¡¹")
        else:
            files_without_content.append(file_path)
            print(f"   æ²¡æœ‰æ‰¾åˆ°å¾…ç¿»è¯‘é¡¹")
    
    print(f"\nğŸ“Š ç»Ÿè®¡ç»“æœ:")
    print(f"   æœ‰å†…å®¹éœ€ç¿»è¯‘çš„æ–‡ä»¶: {len(files_with_content)} ä¸ª")
    print(f"   æ²¡æœ‰å†…å®¹éœ€ç¿»è¯‘çš„æ–‡ä»¶: {len(files_without_content)} ä¸ª")
    
    if files_without_content:
        print(f"\nğŸ“ æ²¡æœ‰ç¿»è¯‘å†…å®¹çš„æ–‡ä»¶åˆ—è¡¨:")
        for file_path in files_without_content:
            print(f"   - {file_path}")
    
    if not files_with_content:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•éœ€è¦ç¿»è¯‘çš„å†…å®¹")
        return
    
    # å¤„ç†æœ‰å†…å®¹çš„æ–‡ä»¶
    for file_path, items in files_with_content:
        print(f"\nğŸ”„ å¼€å§‹ç¿»è¯‘æ–‡ä»¶: {file_path} ({len(items)} ä¸ªé¡¹ç›®)")
        
        # æå–æ‰€æœ‰éœ€è¦ç¿»è¯‘çš„æ–‡æœ¬
        texts_to_translate = [item['value'] for item in items]
        
        # åˆ†å—ç¿»è¯‘
        translated_texts = translate_texts_in_blocks(texts_to_translate)
        
        # ç¡®ä¿ç¿»è¯‘ç»“æœæ•°é‡åŒ¹é…
        if len(translated_texts) != len(items):
            print("âš ï¸ è­¦å‘Šï¼šç¿»è¯‘ç»“æœæ•°é‡ä¸åŸæ–‡ä¸ç¬¦ï¼")
            # ç”¨åŸæ–‡è¡¥é½
            while len(translated_texts) < len(items):
                translated_texts.append(items[len(translated_texts)]['value'])
        
        # å‡†å¤‡æ›´æ–°æ•°æ®
        updates = []
        for i, item in enumerate(items):
            update_item = {
                'line_num': item['line_num'],
                'original_value': item['value'],
                'translated_value': translated_texts[i],
                'original_line': item['original_line'],
                'type': item['type']
            }
            
            if item['type'] in ['key_value', 'colon_value']:
                update_item['key'] = item['key']
            elif item['type'] == 'csv_cell':
                update_item['column_index'] = item['column_index']
                update_item['original_line'] = item['original_line']
            
            updates.append(update_item)
        
        # æ›´æ–°æ–‡ä»¶
        update_file_with_translations(file_path, updates)
    
    print(f"\nâœ… æ‰¹é‡ç¿»è¯‘å®Œæˆï¼å¤„ç†äº† {len(files_with_content)} ä¸ªæ–‡ä»¶")

def main():
    parser = argparse.ArgumentParser(description='æ‰¹é‡æ•°æ®æ–‡ä»¶ç¿»è¯‘å·¥å…·')
    parser.add_argument('--pattern', '-p', help='æ–‡ä»¶åæ¨¡å¼è¿‡æ»¤å™¨')
    parser.add_argument('--max-files', '-m', type=int, help='æœ€å¤§å¤„ç†æ–‡ä»¶æ•°')
    parser.add_argument('--start-index', '-s', type=int, default=0, help='å¼€å§‹å¤„ç†çš„æ–‡ä»¶ç´¢å¼•')
    parser.add_argument('--analyze-only', '-a', action='store_true', help='ä»…åˆ†ææ–‡ä»¶ï¼Œä¸è¿›è¡Œç¿»è¯‘')
    
    args = parser.parse_args()
    
    print("ğŸš€ æ‰¹é‡æ•°æ®æ–‡ä»¶ç¿»è¯‘å·¥å…·")
    print("ğŸ“‹ åŠŸèƒ½ï¼šç¿»è¯‘.datå’Œ.txtæ–‡ä»¶ä¸­çš„æ–‡æœ¬å†…å®¹")
    print("   - ç­‰å·åé¢çš„å†…å®¹")
    print("   - å†’å·åé¢çš„å†…å®¹")
    print("   - æ²¡æœ‰ç­‰å·å’Œå†’å·çš„æ•´è¡Œå†…å®¹")
    print("ğŸš« è·³è¿‡ï¼šæ•°å­—ã€ç§‘å­¦è®¡æ•°æ³•ã€æ–‡ä»¶è·¯å¾„ã€å¸¦ä¸­æ‹¬å·çš„å†…å®¹")
    print("-" * 50)
    
    if args.analyze_only:
        print("ğŸ” ä»…åˆ†ææ¨¡å¼ï¼šåªåˆ†ææ–‡ä»¶ï¼Œä¸è¿›è¡Œç¿»è¯‘")
        analyze_files_only(args.pattern, args.max_files, args.start_index)
    else:
        process_files_batch(args.pattern, args.max_files, args.start_index)

def analyze_files_only(file_pattern=None, max_files=None, start_index=0):
    """ä»…åˆ†ææ–‡ä»¶ï¼Œä¸è¿›è¡Œç¿»è¯‘"""
    # è·å–æ‰€æœ‰.datå’Œ.txtæ–‡ä»¶
    if file_pattern:
        dat_files = glob.glob(f"*{file_pattern}*.dat")
        txt_files = glob.glob(f"*{file_pattern}*.txt")
    else:
        dat_files = glob.glob("*.dat")
        txt_files = glob.glob("*.txt")
    
    all_files = dat_files + txt_files
    
    # æ’é™¤å·²ç¿»è¯‘çš„æ–‡ä»¶
    all_files = [f for f in all_files if not f.endswith('_translated.dat') and not f.endswith('_translated.txt')]
    
    if start_index > 0:
        all_files = all_files[start_index:]
    
    if max_files:
        all_files = all_files[:max_files]
    
    if not all_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•åŒ¹é…çš„.datæˆ–.txtæ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(all_files)} ä¸ªæ–‡ä»¶å¾…åˆ†æ")
    
    # åˆ†ææ¯ä¸ªæ–‡ä»¶
    files_with_content = []
    files_without_content = []
    
    for file_path in all_files:
        print(f"ğŸ“– åˆ†ææ–‡ä»¶: {file_path}")
        items = extract_translatable_content(file_path)
        if items:
            files_with_content.append((file_path, items))
            print(f"   æ‰¾åˆ° {len(items)} ä¸ªå¾…ç¿»è¯‘é¡¹")
        else:
            files_without_content.append(file_path)
            print(f"   æ²¡æœ‰æ‰¾åˆ°å¾…ç¿»è¯‘é¡¹")
    
    print(f"\nğŸ“Š ç»Ÿè®¡ç»“æœ:")
    print(f"   æœ‰å†…å®¹éœ€ç¿»è¯‘çš„æ–‡ä»¶: {len(files_with_content)} ä¸ª")
    print(f"   æ²¡æœ‰å†…å®¹éœ€ç¿»è¯‘çš„æ–‡ä»¶: {len(files_without_content)} ä¸ª")
    
    if files_without_content:
        print(f"\nğŸ“ æ²¡æœ‰ç¿»è¯‘å†…å®¹çš„æ–‡ä»¶åˆ—è¡¨:")
        for file_path in files_without_content:
            print(f"   - {file_path}")
    
    if files_with_content:
        print(f"\nğŸ“ æœ‰ç¿»è¯‘å†…å®¹çš„æ–‡ä»¶åˆ—è¡¨:")
        total_items = 0
        for file_path, items in files_with_content:
            print(f"   - {file_path} ({len(items)} é¡¹)")
            total_items += len(items)
        print(f"\nğŸ“Š æ€»è®¡å¾…ç¿»è¯‘é¡¹ç›®: {total_items} ä¸ª")

if __name__ == "__main__":
    main()